---
title: Sound
layout: compform_chapter.pug

image: /sound/images/og_image.png
hero_title: Comp Sound
description: Make some noise using the p5 sound library.
software: p5.js + p5.sound
---

## Sound

### p5.js Sound Library

<div class="sidebar link-box">

[**p5.sound** API Reference](https://p5js.org/reference/p5.sound)

[**p5.sound** Examples](https://p5js.org/examples/)

</div>

In addition to the basic drawing API, p5.js includes add-on [libraries](https://p5js.org/libraries/). The [parameters](../parameters) chapter introduces the p5.dom library, and the examples in this chapter use the p5.sound library. The p5.sound library builds on the [Web Audio](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API) API and provides functions for generating tones, playing recorded sounds, and visualizing the waveform and spectrum of sounds. I highly suggest taking a look at **all** of the sound examples to get an idea of what the sound library can do.

This chapter will focus on playing and visualizing pre-recorded sound assets. The [Comp Music](../music) chapter talks more about sound synthesis.

{% slides %}
{% include slides.yaml %}
{% endslides %}

<div class="discussion">

## Drawings and Sounds

Compare a basic p5.js drawing with a p5.audio sketch. What do they have in common? How are they different?

### Hello, p5.js!

```javascript
let myImg;

function preload() {
  myImg = loadImage("images/world.jpg");
}

function setup() {
  createCanvas(500, 500);
}

function draw() {
  image(myImg, 0, 0);
}
```

### Hello, p5.sound!

```javascript
let mySound;

function preload() {
  mySound = loadSound("sounds/hack-comp.wav");
}

function setup() {
  mySound.loop(0, 1, 1, 0, 4);
}
```

</div>

### Computers, Light, Sound, and People

<div class="sidebar link-box">

[**Light and Sound** Lecture Notes](./light_and_sound.html)

</div>

Light and sound flow through our environment as electromagnetic and air pressure waves. Our eyes and our ears collect data about these waves and our visual and auditory cortexes process that data to create information. Though they work in different ways, both of these sensory systems are powerful. We can take advantage of these systems by choosing the types of forms we create.

<!--[[This last sentence is unclear to me...I'll work on it.]]-->

## Playing Sound with p5.js

<!--
### Hello, Sound!

<div class="s-lab">
/sound/sketches/hello_sound.js
</div>

### Changing the Frequency

<div class="s-lab">
/sound/sketches/oscillator.js
</div>

### Modulating the Frequency

<div class="s-lab">
/sound/sketches/modulator.js
</div> -->

### Playing Recorded Sounds

p5.js makes it pretty easy to play sound assets, like this audio clip from [Hackers (1995)](http://www.imdb.com/title/tt0113243/).

{% js-lab "sketches/hello_play.js" %}

<div class="callout warn">

Chrome won't start playing sound on a page until the user performs a "gesture" on that page, so starting a sound in `setup()` won't work consistently. These examples start audio on a button press.

[Web Audio Autoplay Policy](https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio)

</div>

### Changing Rate + Pitch

The second parameter to `play()` controlls the rate of playback. If you play a sound faster the pitch will go up; play it slower and the pitch will go down. p5 cannot change the pitch of a sound without changing its length.

{% js-lab "sketches/hello_pitch.js" %}

### Looping

This example loads an audio file twice and then plays two loops at once. The looping end time is slightly different so the playback falls out of sync.

{% js-lab "sketches/two_loops.js" %}

### Drum Kit

This example uses `frameCount` to keep time and play a beat with drum samples. This works for a quick sketch, but `frameCount` isn't a great timekeeping source, so you might notice hitches in your rhythm. The [Tone.js](https://tonejs.github.io) lets you precisely schedule when samples are played, and might be a better choice if you want to make music.

{% js-lab "sketches/hello_drum.js" %}

### Bounce

This example doesn't have any sound in it. Add sound as part of the coding challenges below

{% js-lab "sketches/bounce.js" %}

## Capturing Output

p5.sound provides methods for recording the sound generated by your program and saving it to a file. The following function records `length` milliseconds of audio and saves it as `output.wav`.

Your audio may sound fine at run time but clipped when you play back the `.wav`. If this happens, try reducing the volume of the sounds you generate.

If you can't get good quality audio capture from p5.SoundRecorder, you might get better results using a screen recording program like Quicktime Player.

```javascript
// uses the p5 SoundRecorder and SoundFile classes to record the audio output.
// begins recording when called. records for _length_ time in milliseconds.
function record(length) {
  const soundRecorder = new p5.SoundRecorder();
  const soundFile = new p5.SoundFile();
  soundRecorder.record(soundFile);
  setTimeout(function () {
    console.log("Recording Complete");
    soundRecorder.stop();
    save(soundFile, "output.wav");
  }, length);
}
```

<div class="activity challenges">

## Coding Challenges

Explore this chapter's example code by completing the following challenges.{intro}

### Modify the Drum Kit Example

1. Make kick play twice per second. `•`
1. Create your own beat. `••`

### Modify the Bounce Example

1. Add a drum sound when the ball bounces. `••`
1. Add a little randomness to the playback rate of the sound each time the ball bounces. This little trick can add some texture to sound effects. `•••`
   {continue}

</div>

## Visualizing Sound with p5.js

### Cuepoints

This example adds a single cuepoint to the sound at 1.7 seconds. When playback passes that specific time, `cueBig()` is called.

{% js-lab "sketches/hello_cue.js" %}

### Volume

This example uses `p5.Amplitude()` to track and visualize the volume/loudness of the entire sound.

{% js-lab "sketches/volume.js" %}

### Wave

This example uses `p5.FFT()` to track the and visualize the waveform of the sound.

{% js-lab "sketches/wave.js" %}

### FFT

The Fast Fourier Transform transforms a signal from the time domain to the frequency domain. For audio analysis that means the FFT can tell the strength of different frequencies—bass, mids, treble—in an audio buffer.

For a visual exploration of FFT, see this excellent video by 3Blue1Brown [But what is the Fourier Transform? A visual introduction](https://www.youtube.com/watch?v=spUNpyF58BY).

{% js-lab "sketches/fft.js" %}

<!-- <div class="activity">

## In-class Challenge

Display a little melody.

</div> -->

<div class="activity challenges">

## Coding Challenges

Explore this chapter's example code by completing the following challenges.{intro}

### Modify the Cuepoints Example

1. Move the cuepoint time so the flash aligns with the word "computers". `•`
2. Show the text "Big Trouble" and "Computers". Sync it to the sound. `••`

### Create a p5.sound project from scratch.

1. Create a new project on the p5 web editor.
2. Verify that the html file includes the p5.sound library.
3. Find a sound file and add it to your project.
4. Use p5.sound to play the sound file.
   {continue}

</div>

## Making Sounds from Scratch

You can create an empty soundFile object with `new p5.SoundFile()` and generate the sound data yourself with Javascript. To do so you will create and fill a [Float32Array](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Float32Array) and then attach it to the SoundFile object with `setBuffer()`.

{% js-lab "sketches/buffer.js" %}

Creating sounds this way lets you work at the lowest possible level: individual samples. This can be fun, and it gives you complete control, but you will probably need to reinvent some basics.

P5.js has functions for working with oscillators, envelopes, and effects if you want to work at a little higher level. You might also consider using a dedicated Javascript sound synthesis library like [Tone.js](https://tonejs.github.io), which is a little more powerful and better documented.

<div class="activity challenges">

## Coding Challenges

Explore this chapter's example code by completing the following challenges.{intro}

### Modify the Making Sounds from Scratch Example

1. The example has several examples of generating sounds commented out. Comment in each sound generator and try them out. `•`
1. Create a sound that is static for .5 seconds followed by a low-pitched tone for .5 seconds. `••`
   {continue}

</div>

<div class="assignment">

## Keep Sketching!

### Sketch

Keep sketching. Make a bunch of noise!

### Challenge 1: Synesthesia 1

Choose a 15-second video clip. Use p5.sound to create a new soundtrack for your clip. Combine audio and sound.

### Challenge 2: Synesthesia 2

Choose a 15-second audio clip. Use p5.sound to generate graphics driven by the sound. Combine audio and sound.

### Challenge 3: Synesthesia 3

Create a 15-second procedurally generated audio and visual form. The audio and video should be generated from the same process.

</div>

## Explore

<div class="link-box">

[**Color from Hexcodes to Eyeballs** Technical Essay](http://jamie-wong.com/post/color/)
Jamie Wong describes the each step of how color is expressed and interpreted.

[**Compform '16 Comp Music** Lecture Notes](http://psam3060-d-s16.github.io/class_notes/week_9/)
Compform '16 week on computational music.

[**Compform '16 Comp Music Examples** Lecture Notes](http://psam3060-d-s16.github.io/class_notes/week_9/docco_out/)
Examples from Compform '16 week on computational music.

[**WebMidiAPIShim** Library](https://github.com/cwilso/WebMIDIAPIShim)
A javascript shim for accessing midi devices.

[**Fourier Transform** 3Blue1Brown](https://www.youtube.com/watch?v=spUNpyF58BY)
A great visual introduction to the Fourier transform.

[**An Interactive Introduction to Fourier Transforms** Demo](http://www.jezzamon.com/fourier/index.html)
Visual and interactive demos of Fourier Transforms for both sound and drawing.

</div>
